{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3\n",
    "\n",
    " |     vis_grid      |  vis_rays |\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](images/Q1.3.1.png)  |  ![Alt Text](images/Q1.3.2.png)\n",
    "\n",
    "## Q1.4\n",
    "![Alt Text](images/Q1.4.png)\n",
    "\n",
    "## Q1.5\n",
    " |     gif      |  depth |\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](images/part_1.gif)  |  ![Alt Text](images/Q1.5.2.png)\n",
    "\n",
    "## Q2.3\n",
    "```\n",
    "Box center: (0.250, 0.250, 0.000)\n",
    "Box side lengths: (2.005, 1.503, 1.503)\n",
    "```\n",
    " |     my output      |  TA's output |\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](images/part_2.gif)  |  ![Alt Text](ta_images/part_2.gif)\n",
    "\n",
    "\n",
    "## Q3\n",
    "Following is the output of the default setting `nerf_lego`.\n",
    "\n",
    "![Alt Text](images/part_3.gif)\n",
    "\n",
    "## Q4.3\n",
    "\n",
    "In this part I am curious about the difference of sampling different number of points in one ray. In this section, I compared the output from 64 points per ray and 128 points per ray. With 128 points sampled per ray, the output model have a better result in some details, i.e., the wheel in the back. \n",
    "\n",
    "Due ot the GPU memory limitation, I didn't generate the result with more points. The result of the experiment is listed below.\n",
    "\n",
    " |points per ray |     64      |  128 |\n",
    ":-----:|:-------------------------:|:-------------------------:\n",
    "output | ![Alt Text](images/highres_64part_3.gif)  |  ![Alt Text](images/highres_128part_3.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
